---
title: "Untitled"
author: "Edgart Flores"
date: "12/17/2020"
output: html_document
---
#-------------------------------------------------------------------------------------------------------------------------------------------------
#                                                           Porcentajes totales
# incluyendo los DGGT (este grupo es varias ordenes de magnitud mas altas que el resto de grupos)
#-------------------------------------------------------------------------------------------------------------------------------------------------

```{r setup, include=FALSE}
library(dplyr)
library(readr)
library(tidyverse)
library(latex2exp)
library(readxl)
library(here) 
library(broom)
library(ggplot2)
library(RColorBrewer)
library(scales)
library(reshape2)
library(dendextend)
library(cowplot)
library(ggdendro)
library(graphics)
library(vegan)
library(pvclust)
library(cluster)
library(factoextra)
library(magrittr)
library(janitor)
library(ade4) 
#library(adespatial) 
library(gclus) 
library(cluster) 
library(FD)
library(ggpubr)

library(scico)
library(pals)
library(viridis)
library(lmodel2)
library(ggpmisc)
library(wesanderson)
library(RColorBrewer)
library(RColorBrewer)
``` 


#-----------------------------------------------------------------------------------------------------------------------------------------------------------
#
#                                                      CLASES OF IPLs
#-----------------------------------------------------------------------------------------------------------------------------------------------------------
# CLASES RELATIVIZADAS POR ID 

```{r, message=FALSE}
final_corrected<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/04.id_class_relab_by_id_no_DGGT.csv")
#final_corrected<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/03.id_class_relab_by_id.csv")
```


# control + Shift + C = descomento todo
```{r, message=FALSE}
final_corrected <- final_corrected  %>%
  mutate(id_new =
           case_when(grepl("H03_01_7890m", id) ~ "Hadal_Sed_H3_0_1cm_7890m",
                     grepl("H03_12_7890m", id) ~ "Hadal_Sed_H3_1_2cm_7890m",
                     grepl("H03_23_7890m", id) ~ "Hadal_Sed_H3_2_3cm_7890m",
                     grepl("H04_01_8063m", id) ~ "Hadal_Sed_H4_0_1cm_8063m",
                     grepl("H04_12_8063m", id) ~ "Hadal_Sed_H4_1_2cm_8063m",
                     grepl("H04_23_8063m", id) ~ "Hadal_Sed_H4_2_3cm_8063m",
                     grepl("H08_01_7734m", id) ~ "Hadal_Sed_H8_0_1cm_7734m",
                     grepl("H08_12_7734m", id) ~ "Hadal_Sed_H8_1_2cm_7734m",
                     grepl("H08_23_7734m", id) ~ "Hadal_Sed_H8_2_3cm_7734m",
                     
                     grepl("B04_1200m", id) ~ "Bathyal_Sed_B04_1200m",
                     grepl("B11_1113m", id) ~ "Bathyal_Seds_B11_1113m",
                     grepl("B05_957m", id) ~ "Bathyal_Sed_B05_957m",
                     grepl("B07_920m", id) ~ "Bathyal_Sed_B07_920m",
                     grepl("B22_545m", id) ~ "Bathyal_Sed_B22_545m",
                     grepl("B08_539m", id) ~ "Bathyal_Sed_B08_539m",
                     grepl("B12_529m", id) ~ "Bathyal_Sed_B12_529m",
                     
                     grepl("Mesopelagic_T5_0.3_750m", id) ~ "Mesopelagic_T5_0.3_750m",
                     grepl("Mesopelagic_T5_2.7_750m", id) ~ "Mesopelagic_T5_2.7_750m",
                     grepl("Mesopelagic_T3_0.3_750m", id) ~ "Mesopelagic_T3_0.3_750m",
                     grepl("Mesopelagic_T3_2.7_750m", id) ~ "Mesopelagic_T3_2.7_750m",
                     grepl("Core_OMZ_T5_0.3_250m", id) ~ "Core_OMZ_T5_0.3_250m",
                     grepl("Core_OMZ_T5_2.7_250m", id) ~ "Core_OMZ_T5_2.7_250m",
                     grepl("Core_OMZ_T3_0.3_250m", id) ~ "Core_OMZ_T3_0.3_250m",
                     grepl("Core_OMZ_T3_2.7_250m", id) ~ "Core_OMZ_T3_2.7_250m",
                     grepl("Upper_OMZ_T5_0.3_60m", id) ~ "Upper_OMZ_T5_0.3_60m",
                     grepl("Upper_OMZ_T5_2.7_60m", id) ~ "Upper_OMZ_T5_2.7_60m",
                     grepl("Upper_OMZ_T3_0.3_55m", id) ~ "Upper_OMZ_T3_0.3_55m",
                     grepl("Upper_OMZ_T3_2.7_55m", id) ~ "Upper_OMZ_T3_2.7_55m",
                     grepl("Lower_Oxy_T5_0.3_45m", id) ~ "Lower_Oxy_T5_0.3_45m",
                     grepl("Lower_Oxy_T5_2.7_45m", id) ~ "Lower_Oxy_T5_2.7_45m",
                     grepl("Upper_Oxy_T5_0.3_35m", id) ~ "Upper_Oxy_T5_0.3_35m",
                     grepl("Upper_Oxy_T5_2.7_35m", id) ~ "Upper_Oxy_T5_2.7_35m",
                     grepl("Chl_Max_T5_0.3_28m", id) ~ "Chl_Max_T5_0.3_28m",
                     grepl("Chl_Max_T5_2.7_28m", id) ~ "Chl_Max_T5_2.7_28m",
                     grepl("Lower_Oxy_T3_0.3_25m", id) ~ "Lower_Oxy_T3_0.3_25m",
                     grepl("Lower_Oxy_T3_2.7_25m", id) ~ "Lower_Oxy_T3_2.7_25m",
                     grepl("Upper_Oxy_T3_0.3_14m", id) ~ "Upper_Oxy_T3_0.3_14m",
                     grepl("Upper_Oxy_T3_2.7_14m", id) ~ "Upper_Oxy_T3_2.7_14m",
                     grepl("Chl_Max_T3_0.3_9m", id) ~ "Chl_Max_T3_0.3_9m",
                      grepl("Chl_Max_T3_2.7_9m", id) ~ "Chl_Max_T3_2.7_9m"               
                     ))
```


# remove el id 03-R1 o el row que quieras
```{r, message=FALSE}
final_corrected <- subset(final_corrected,  ! paste(id,sep="_") %in% c("3_01R") )
final_corrected <- subset(final_corrected,  ! paste(id,sep="_") %in% c("NA") )
```

```{r cars}
# NECESITO SOLO ID, compound y relab
final_corrected <- select(final_corrected, id_new, class, relab) 
final_corrected <- dcast(final_corrected, id_new ~ class, value.var = c("relab"))
final_corrected <- data.frame(final_corrected[,-1], row.names=final_corrected[,1])

final_corrected[is.na(final_corrected)] <- 0 # transformar todos los NA en zeros
```



# caso especial = necesito transponer esta data para un cluster de probabilidad

```{r cars}
Approximately_Unbiased <- data.frame(t(final_corrected))
```

# incluso esto es confuso porque existe otro metodo method = "silhouette" que puede dar valores distintos

# En este análisis, a partir de 5 clusters la reducción en la suma total de cuadrados internos parece estabilizarse, indicando que K = 5 es una buena opción.

# Ward: Se trata de un método general. La selección del par de clusters que se combinan en cada paso del agglomerative hierarchical clustering se basa en el valor óptimo de una función objetivo, pudiendo ser esta última cualquier función definida por el analista. El conocido método Ward’s minimum variance es un caso particular en el que el objetivo es minimizar la suma total de varianza intra-cluster. En cada paso, se identifican aquellos 2 clusters cuya fusión conlleva menor incremento de la varianza total intra-cluster. La implementación en R de este método ha sido causa de confusiones (Ward’s Hierarchical Agglomerative Clustering Method: Which Algorithms Implement Ward’s Criterion? by Fionn Murtagh y Pierre Legendre). Si se emplea la función hclust() se tiene que especificar method = "ward.D2", mientras que en la función agnes() es method = ward".

# Average: Se calcula la distancia entre todos los posibles pares formados por una observación del cluster A y una del cluster B. El valor promedio de todas ellas se selecciona como la distancia entre los dos clusters (mean intercluster dissimilarity).



# empece con complete y average
# con distncia euclidean y cambie a Manhattan (euclidea)

```{r cars}
hc_euclidea_completo <- hclust(d = dist(x = final_corrected, method = "euclidea"),
                               method = "average")

#, palette = "jco" in fviz_dend
a <- fviz_dend(x = hc_euclidea_completo, k = 5, cex = 0.5, horiz = T,  palette = "Set1") +
  #geom_hline(yintercept = 0.57, linetype = "dashed") +
  labs(title = "Herarchical clustering",
       subtitle = "Distancia euclídea, Lincage complete, K=5")
a       
```      

```{r cars}
# ,palette = "jco" in fviz_cluster
b <- fviz_cluster(object = list(data=final_corrected, cluster=cutree(hc_euclidea_completo, k=5)),
             ellipse.type = "convex", repel = TRUE, show.clust.cent = FALSE, palette = "Set1",
             labelsize = 8)  +
  labs(title = "Hierarchical clustering + Proyección PCA",
       subtitle = "Distancia euclídea, Lincage complete, K=4") +
  theme_bw() +
  theme(legend.position = "bottom")
```


```{r cars}
# figure_class<- ggarrange (a,b, 
#                     labels = c("A","B"),
#                     ncol = 2, nrow = 2)
# figure_class

library("cowplot")
figure_class <- ggdraw() +
  draw_plot(a, x = 0, y = 0, width = 0.35, height = 1) +
  draw_plot(b, x = 0.37, y = 0, width = 0.66, height = 0.97) +
  draw_plot_label(label = c("A", "B"), size = 8,
                  x = c(0, 0.5), y = c(1, 1))
figure_class
```


#además de mi prueba de Kmeans que metodo puedo usar para saber si mi cluster es significativo?

# simprof <- A tool for determining the number of significant clusters produced using hclust() with the assumption of no a priori groups.

# O CALCULAR LAS PROBABILIDADES!!!

```{r cars}
# Significancia de los clusters
Estudiar la significancia de clusters consiste en calcular la probabilidad de que las agrupaciones se obtengan simplemente por azar. Se han desarrollado diferentes aproximaciones para cuantificar la significancia, algunas basadas en métodos de resampling y otras en la incorporación de información externa.

# Significancia de hierarchical clusters por resampling

La idea detrás de esta estrategia es emplear bootstrap-resampling para simular pseudo-muestras con las que se repetir el clustering y luego evaluar la frecuencia con la que se repite cada cluster. El paquete pvclust automatiza este proceso para el caso particular de hierarchical clustering, calculando dos tipos de p-value: AU (Approximately Unbiased) p-value y BP (Bootstrap Probability) value, siendo el primero la opción recomendada por los creadores del paquete. Clusters con un valor de AU igual o por encima del 95% tienen fiabilidad muy alta. Se trata de un método que requiere muchos recursos computacionales ya que, para conseguir buena precisión, se necesitan al menos 1000 simulaciones. El paquete incluye la posibilidad de recurrir a computación paralela para reducir el tiempo de computación.
```


#Approximately_Unbiased
# Datos de abundacia relativa de las clases por ID sin GDGT

```{r cars}
Approximately_Unbiased <- data.frame(t(final_corrected))
# Se generan solo 100 pseudo-muestras para agilizar el proceso, pero para casos
# reales los autores no recomiendan bajar de 10000
boot_hc_cluster <- pvclust(data = Approximately_Unbiased, method.dist = "euclidea",
                           method.hclust = "average",
                           nboot = 10, quiet = T)
# Al representar un objeto pvclust se obtiene el dendrograma con los valores de
# AU-pvalue en rojo y BP-values en verde
plot(boot_hc_cluster, cex = 0.8, print.num = F, cex.pv = 0.8)

# Con la función pvrect() se encuadran aquellos clusters significativos para una
# confianza del 95%.
pvrect(x = boot_hc_cluster, alpha = 0.95, pv = "au")

# package ‘tanglegram’ is not available (for R version 4.0.2)
```





#In the dendrogram, the y-axis is simply the value of this distance metric between clusters


#----------------------------------------------------------------------------------------------------------------------------------------------------
#                                                      COMPOUNDS OF IPLs
#----------------------------------------------------------------------------------------------------------------------------------------------------

# anteriomente veníamos ploteando las clases y ahora el objetvio es la caracterización de los compounts 
```{r cars}
# data con GDGTs
all<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/12b.simprof_compound_relab_by_id_no_GDGT.csv", row.names = 1)
# data sin GDGTs
#all<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/12.simprof_compound_relab_by_id_all.csv", row.names = 1)
# aplicar una transpuesta a los datos
```



#, palette = "jco" in fviz_dend
```{r cars}
hc_euclidea_completo <- hclust(d = dist(x = all, method = "euclidea"),
                               method = "average")

fviz_dend(x = hc_euclidea_completo, k = 5, cex = 0.4, horiz = T) +
  #geom_hline(yintercept = 0.57, linetype = "dashed") +
  labs(title = "Herarchical clustering",
       subtitle = "Distancia euclídea, Lincage complete, K=5")
``` 

```{r cars}
library(factoextra)
library(ggpubr)

fviz_cluster(object = list(data=all, cluster=cutree(hc_euclidea_completo, k=5)),
             ellipse.type = "convex", repel = TRUE, show.clust.cent = FALSE, palette = "jco",
             labelsize = 8)  +
  labs(title = "Hierarchical clustering + Proyección PCA",
       subtitle = "Distancia euclídea, Lincage complete, K=5") +
  theme_bw() +
  theme(legend.position = "bottom")
```

# Abundancias relativas por ID (ESTACIÓN) en escala de 0-100% 
# primero revisar que pasa CON GDDTs, considerar la influencia de estos en el resto de la data

```{r cars}
# data con GDGTs
#all<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/12.simprof_compound_relab_by_id_all.csv", row.names = 1)
# data sin GDGTs
all<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/12b.simprof_compound_relab_by_id_no_GDGT.csv", row.names = 1)
# aplicar una transpuesta a los datos
Approximately_Unbiased <- data.frame(t(all))
```

```{r cars}
# Se generan solo 100 pseudo-muestras para agilizar el proceso, pero para casos
# reales los autores no recomiendan bajar de 10000
boot_hc_cluster <- pvclust(data = Approximately_Unbiased, method.dist = "euclidea",
                           method.hclust = "average",
                           nboot = 1000, quiet = TRUE)
# Al representar un objeto pvclust se obtiene el dendrograma con los valores de
# AU-pvalue en rojo y BP-values en verde
plot(boot_hc_cluster, cex = 0.8, print.num = FALSE, cex.pv = 0.8)

# Con la función pvrect() se encuadran aquellos clusters significativos para una
# confianza del 95%.
pvrect(x = boot_hc_cluster, alpha = 0.95, pv = "au")
```

# Abundancias relativas por ID (ESTACIÓN) en escala de 0-100% 
# Ahora ver el order SIN GDDTs

```{r cars}
# data con GDGTs
#all<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/12.simprof_compound_relab_by_id_all.csv", row.names = 1)
# data sin GDGTs
all<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/12b.simprof_compound_relab_by_id_no_GDGT.csv", row.names = 1)
# aplicar una transpuesta a los datos
Approximately_Unbiased <- data.frame(t(all))
```

```{r cars}
# # Significancia de los clusters
# Estudiar la significancia de clusters consiste en calcular la probabilidad de que las agrupaciones se obtengan simplemente por azar. Se han desarrollado diferentes aproximaciones para cuantificar la significancia, algunas basadas en métodos de resampling y otras en la incorporación de información externa.
# 
# # Significancia de hierarchical clusters por resampling
# 
# La idea detrás de esta estrategia es emplear bootstrap-resampling para simular pseudo-muestras con las que se repetir el clustering y luego evaluar la frecuencia con la que se repite cada cluster. El paquete pvclust automatiza este proceso para el caso particular de hierarchical clustering, calculando dos tipos de p-value: AU (Approximately Unbiased) p-value y BP (Bootstrap Probability) value, siendo el primero la opción recomendada por los creadores del paquete. Clusters con un valor de AU igual o por encima del 95% tienen fiabilidad muy alta. Se trata de un método que requiere muchos recursos computacionales ya que, para conseguir buena precisión, se necesitan al menos 1000 simulaciones. El paquete incluye la posibilidad de recurrir a computación paralela para reducir el tiempo de computación.
```

```{r cars}
# Se generan solo 100 pseudo-muestras para agilizar el proceso, pero para casos
# reales los autores no recomiendan bajar de 10000
boot_hc_cluster <- pvclust(data = Approximately_Unbiased, method.dist = "euclidea",
                           method.hclust = "average",
                           nboot = 10000, quiet = TRUE)
# Al representar un objeto pvclust se obtiene el dendrograma con los valores de
# AU-pvalue en rojo y BP-values en verde
plot(boot_hc_cluster, cex = 0.5, print.num = FALSE, cex.pv = 0.6)

# Con la función pvrect() se encuadran aquellos clusters significativos para una
# confianza del 95%.
pvrect(x = boot_hc_cluster, alpha = 0.95, pv = "au")
# package ‘tanglegram’ is not available (for R version 4.0.2)
```

# SOLO SEDIMENTS

```{r cars}
all<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/17.simprof_compound_relab_by_id_no_GDGT_only_sed.csv", row.names = 1)

# aplicar una transpuesta a los datos
Approximately_Unbiased <- data.frame(t(all))
```


```{r cars}
# Se generan solo 100 pseudo-muestras para agilizar el proceso, pero para casos
# reales los autores no recomiendan bajar de 10000
boot_hc_cluster <- pvclust(data = Approximately_Unbiased, method.dist = "euclidea",
                           method.hclust = "average",
                           nboot = 10000, quiet = TRUE)
# Al representar un objeto pvclust se obtiene el dendrograma con los valores de
# AU-pvalue en rojo y BP-values en verde
plot(boot_hc_cluster, cex = 0.8, print.num = FALSE, cex.pv = 0.8)

# Con la función pvrect() se encuadran aquellos clusters significativos para una
# confianza del 95%.
pvrect(x = boot_hc_cluster, alpha = 0.95, pv = "au")
# package ‘tanglegram’ is not available (for R version 4.0.2)
```



```{r cars}
# Se generan solo 100 pseudo-muestras para agilizar el proceso, pero para casos
# reales los autores no recomiendan bajar de 10000
boot_hc_cluster <- pvclust(data = Approximately_Unbiased, method.dist = "euclidea",
                           method.hclust = "average",
                           nboot = 10, quiet = TRUE)
# Al representar un objeto pvclust se obtiene el dendrograma con los valores de
# AU-pvalue en rojo y BP-values en verde
plot(boot_hc_cluster, cex = 0.5, print.num = FALSE, cex.pv = 0.6)

# Con la función pvrect() se encuadran aquellos clusters significativos para una
# confianza del 95%.
pvrect(x = boot_hc_cluster, alpha = 0.95, pv = "au")
# package ‘tanglegram’ is not available (for R version 4.0.2)
```



# Ver el cluster por clases ("nótese que PC es más similar a DGCC que al resto de phospholipids") 
# teber en cuenta el input 
```{r cars}
# Se generan solo 100 pseudo-muestras para agilizar el proceso, pero para casos
# reales los autores no recomiendan bajar de 10000
boot_hc_cluster <- pvclust(data = final_corrected, method.dist = "cor",
                           method.hclust = "average",
                           nboot = 100, quiet = TRUE)
# Al representar un objeto pvclust se obtiene el dendrograma con los valores de
# AU-pvalue en rojo y BP-values en verde
plot(boot_hc_cluster, cex = 0.5, print.num = FALSE, cex.pv = 0.6)

# Con la función pvrect() se encuadran aquellos clusters significativos para una
# confianza del 95%.
pvrect(x = boot_hc_cluster, alpha = 0.95, pv = "au")
# package ‘tanglegram’ is not available (for R version 4.0.2)
```

# la funcion de este codigo no es compatible con la version de R que uso
## package ‘tanglegram’ is not available (for R version 4.0.2)
```{r cars}
tanglegram(dend1 = a, dend2 = b, highlight_distinct_edges = TRUE,
           common_subtrees_color_branches = TRUE)
```


# empece con complete y average
# con distncia euclidean y cambie a Manhattan
```{r cars}
simprof1 <- read.csv("~/Documents/EF_IPL_Processing_new/data_final/12.simprof_compound_relab_by_id_all.csv", row.names = 1)

# numero de cluster
#library(factoextra)
#fviz_nbclust(x = simprof1, FUNcluster = kmeans, method = "wss", k.max = 15, 
#             diss = get_dist(final_corrected, method = "euclidean"), nstart = 50)

#plot cluster

hc_euclidea_completo <- hclust(d = dist(x = simprof1, method = "manhattan"),
                               method = "complete")

fviz_dend(x = hc_euclidea_completo, k = 5, cex = 0.4, horiz = T) +
  geom_hline(yintercept = 0.57, linetype = "dashed") +
  labs(title = "Herarchical clustering",
       subtitle = "Distancia euclídea, Lincage complete, K=5")


```

```{r cars}
fviz_cluster(object = list(data=simprof1, cluster=cutree(hc_euclidea_completo, k=4)),
             ellipse.type = "convex", repel = TRUE, show.clust.cent = FALSE,
             labelsize = 8)  +
  labs(title = "Hierarchical clustering + Proyección PCA",
       subtitle = "Distancia euclídea, Lincage complete, K=4") +
  theme_bw() +
  theme(legend.position = "bottom")
```


# plots de BARRAS

#-------------------------------------------------------------------------------------------------------------------------------------------------
#                                                           Porcentajes totales AHORA SIN GDGT = Se volvió a relativizar
#-------------------------------------------------------------------------------------------------------------------------------------------------
# incluyendo los DGGT (este grupo es varias ordenes de magnitud mas altas que el resto de grupos)

```{r, message=FALSE}
final_corrected1<- read.csv("~/Documents/EF_IPL_Processing_new/data_final/04.id_class_relab_by_id_no_DGGT.csv")
```

```{r, message=FALSE}
final_corrected1 <- final_corrected1  %>%
  mutate(id_new =
           case_when(grepl("H03_01_7890m", id) ~ "Hadal_Sed_H3_0_1cm_7890m",
                     grepl("H03_12_7890m", id) ~ "Hadal_Sed_H3_1_2cm_7890m",
                     grepl("H03_23_7890m", id) ~ "Hadal_Sed_H3_2_3cm_7890m",
                     grepl("H04_01_8063m", id) ~ "Hadal_Sed_H4_0_1cm_8063m",
                     grepl("H04_12_8063m", id) ~ "Hadal_Sed_H4_1_2cm_8063m",
                     grepl("H04_23_8063m", id) ~ "Hadal_Sed_H4_2_3cm_8063m",
                     grepl("H08_01_7734m", id) ~ "Hadal_Sed_H8_0_1cm_7734m",
                     grepl("H08_12_7734m", id) ~ "Hadal_Sed_H8_1_2cm_7734m",
                     grepl("H08_23_7734m", id) ~ "Hadal_Sed_H8_2_3cm_7734m",
                     
                     grepl("B04_1200m", id) ~ "Bathyal_Sed_B04_1200m",
                     grepl("B11_1113m", id) ~ "Bathyal_Seds_B11_1113m",
                     grepl("B05_957m", id) ~ "Bathyal_Sed_B05_957m",
                     grepl("B07_920m", id) ~ "Bathyal_Sed_B07_920m",
                     grepl("B22_545m", id) ~ "Bathyal_Sed_B22_545m",
                     grepl("B08_539m", id) ~ "Bathyal_Sed_B08_539m",
                     grepl("B12_529m", id) ~ "Bathyal_Sed_B12_529m",
                     
                     grepl("Mesopelagic_T5_0.3_750m", id) ~ "Mesopelagic_T5_0.3_750m",
                     grepl("Mesopelagic_T5_2.7_750m", id) ~ "Mesopelagic_T5_2.7_750m",
                     grepl("Mesopelagic_T3_0.3_750m", id) ~ "Mesopelagic_T3_0.3_750m",
                     grepl("Mesopelagic_T3_2.7_750m", id) ~ "Mesopelagic_T3_2.7_750m",
                     grepl("Core_OMZ_T5_0.3_250m", id) ~ "Core_OMZ_T5_0.3_250m",
                     grepl("Core_OMZ_T5_2.7_250m", id) ~ "Core_OMZ_T5_2.7_250m",
                     grepl("Core_OMZ_T3_0.3_250m", id) ~ "Core_OMZ_T3_0.3_250m",
                     grepl("Core_OMZ_T3_2.7_250m", id) ~ "Core_OMZ_T3_2.7_250m",
                     grepl("Upper_OMZ_T5_0.3_60m", id) ~ "Upper_OMZ_T5_0.3_60m",
                     grepl("Upper_OMZ_T5_2.7_60m", id) ~ "Upper_OMZ_T5_2.7_60m",
                     grepl("Upper_OMZ_T3_0.3_55m", id) ~ "Upper_OMZ_T3_0.3_55m",
                     grepl("Upper_OMZ_T3_2.7_55m", id) ~ "Upper_OMZ_T3_2.7_55m",
                     grepl("Lower_Oxy_T5_0.3_45m", id) ~ "Lower_Oxy_T5_0.3_45m",
                     grepl("Lower_Oxy_T5_2.7_45m", id) ~ "Lower_Oxy_T5_2.7_45m",
                     grepl("Upper_Oxy_T5_0.3_35m", id) ~ "Upper_Oxy_T5_0.3_35m",
                     grepl("Upper_Oxy_T5_2.7_35m", id) ~ "Upper_Oxy_T5_2.7_35m",
                     grepl("Chl_Max_T5_0.3_28m", id) ~ "Chl_Max_T5_0.3_28m",
                     grepl("Chl_Max_T5_2.7_28m", id) ~ "Chl_Max_T5_2.7_28m",
                     grepl("Lower_Oxy_T3_0.3_25m", id) ~ "Lower_Oxy_T3_0.3_25m",
                     grepl("Lower_Oxy_T3_2.7_25m", id) ~ "Lower_Oxy_T3_2.7_25m",
                     grepl("Upper_Oxy_T3_0.3_14m", id) ~ "Upper_Oxy_T3_0.3_14m",
                     grepl("Upper_Oxy_T3_2.7_14m", id) ~ "Upper_Oxy_T3_2.7_14m",
                     grepl("Chl_Max_T3_0.3_9m", id) ~ "Chl_Max_T3_0.3_9m",
                      grepl("Chl_Max_T3_2.7_9m", id) ~ "Chl_Max_T3_2.7_9m"               
                     ))
```




# remove el id 03-R1 o el row que quieras
```{r, message=FALSE}
final_corrected1 <- subset(final_corrected1,  ! paste(id_new,sep="_") %in% c("3_01R") )
final_corrected1 <- subset(final_corrected1,  ! paste(id_new,sep="_") %in% c("NA") )
```

# first separte by diferent Class (see column class)
```{r, message=FALSE}
# BETAINE LIPIDS--> HERE there is 3 DGTS,DGTA,DGCC
#BL <- subset(final_corrected, Class == "BL") 

DGTS <- subset(final_corrected1, class == "DGTS") 
DGTA <- subset(final_corrected1, class == "DGTA")
DGCC <- subset(final_corrected1, class == "DGCC") 

#GLICOLIPIDS
MGDG <- subset(final_corrected1, class == "MGDG")
DGDG <- subset(final_corrected1, class == "DGDG")
SQDG <- subset(final_corrected1, class == "SQ")

#Phospholipids
PC <- subset(final_corrected1, class == "PC")
PE <- subset(final_corrected1, class == "PE")
PG <- subset(final_corrected1, class == "PG")

# Aditinally
PME_PDME <- subset(final_corrected1, class == "PME/PDME")
GDGT <- subset(final_corrected1, class == "GDGT")
Other <- subset(final_corrected1, class == "Other")

# sin GDGT
#todos <- subset(final_corrected, class %in% c("BL","MGDG","DGDG","SQ","PC","PE","PG","PME/PDME","Other"))


#AT <- subset (final_corrected, SampleType == "Inner trench")
#slope <- subset (final_corrected, SampleType == "Continental slope")

```


# plan A
```{r, message=FALSE}
# ORDEN DE ACUERDO A LA PROFUNDIDAD
final_corrected1$id_new <- factor(final_corrected1$id_new, levels = c(
"Hadal_Sed_H4_2_3cm_8063m",
"Hadal_Sed_H4_1_2cm_8063m",
"Hadal_Sed_H4_0_1cm_8063m",
"Hadal_Sed_H8_2_3cm_7734m",
"Hadal_Sed_H8_1_2cm_7734m",
"Hadal_Sed_H8_0_1cm_7734m",
"Hadal_Sed_H3_2_3cm_7890m",
"Hadal_Sed_H3_1_2cm_7890m",
"Hadal_Sed_H3_0_1cm_7890m",
"Bathyal_Sed_B04_1200m",
"Bathyal_Seds_B11_1113m",
"Bathyal_Sed_B05_957m",
"Bathyal_Sed_B07_920m",
"Bathyal_Sed_B22_545m",
"Bathyal_Sed_B08_539m",
"Bathyal_Sed_B12_529m",
"Mesopelagic_T5_0.3_750m", "Mesopelagic_T5_2.7_750m",
"Mesopelagic_T3_0.3_750m", "Mesopelagic_T3_2.7_750m",
"Core_OMZ_T5_0.3_250m", "Core_OMZ_T5_2.7_250m",
"Core_OMZ_T3_0.3_250m","Core_OMZ_T3_2.7_250m",
"Upper_OMZ_T5_0.3_60m",	"Upper_OMZ_T5_2.7_60m",
"Upper_OMZ_T3_0.3_55m", "Upper_OMZ_T3_2.7_55m",
"Lower_Oxy_T5_0.3_45m","Lower_Oxy_T5_2.7_45m",
"Upper_Oxy_T5_0.3_35m","Upper_Oxy_T5_2.7_35m",
"Chl_Max_T5_0.3_28m", "Chl_Max_T5_2.7_28m",
"Lower_Oxy_T3_0.3_25m","Lower_Oxy_T3_2.7_25m",
"Upper_Oxy_T3_0.3_14m" , "Upper_Oxy_T3_2.7_14m",
"Chl_Max_T3_0.3_9m", "Chl_Max_T3_2.7_9m")
)




p <- ggplot(data=final_corrected1, aes(x=relab, y=id_new, fill=class))
g <- p + geom_bar(aes(y=id_new), stat="identity", position= "stack") + 
  #facet_wrap(~SampleType + SampleType2, scales = "free_y", nrow = 4, strip.position = "right") +
  #facet_grid(SampleType + SampleType2~. , scales = "free_y", space = "free_y") + 
  theme_bw() +
scale_fill_manual(values = colorRampPalette(brewer.pal(12, "Spectral"))(11)) +
  
  xlab("Relative abundance") + ylab(" ") +
  theme(legend.title = element_blank(), legend.position = "right") + 
   theme(legend.key.height = unit(0.5, "mm"))  +
   theme(legend.key.width  = unit(5, "mm"))  +
   theme(legend.key.size  = unit(0.3, "mm"))  +
   theme(legend.title = element_text(size = 9), 
               legend.text = element_text(size = 7)) +
    guides(fill=guide_legend(ncol = 1))  
    
g

```


# plan B
```{r, message=FALSE}
# ORDEN DE ACUERDO A LA PROFUNDIDAD
final_corrected1$id_new <- factor(final_corrected1$id_new, levels = c(
"Upper_OMZ_T3_2.7_55m",
"Mesopelagic_T5_2.7_750m",
"Core_OMZ_T5_2.7_250m",
"Upper_OMZ_T5_2.7_60m",
"Lower_Oxy_T3_2.7_25m",
"Hadal_Sed_H4_2_3cm_8063m",
"Hadal_Sed_H3_1_2cm_7890m",
"Hadal_Sed_H8_0_1cm_7734m",
"Upper_OMZ_T3_0.3_55m",
"Mesopelagic_T3_2.7_750m",
"Mesopelagic_T5_0.3_750m",
"Mesopelagic_T3_0.3_750m",
"Hadal_Sed_H8_1_2cm_7734m",
"Hadal_Sed_H3_0_1cm_7890m",
"Hadal_Sed_H3_2_3cm_7890m",
"Bathyal_Sed_B04_1200m",
"Hadal_Sed_H4_0_1cm_8063m",
"Bathyal_Sed_B08_539m",
"Bathyal_Sed_B07_920m",
"Hadal_Sed_H4_1_2cm_8063m",
"Bathyal_Sed_B22_545m",
"Hadal_Sed_H8_2_3cm_7734m",
"Bathyal_Seds_B11_1113m",
"Bathyal_Sed_B12_529m",
"Bathyal_Sed_B05_957m",
"Upper_Oxy_T3_0.3_14m",
"Core_OMZ_T3_2.7_250m",
"Chl_Max_T5_2.7_28m",
"Upper_OMZ_T5_0.3_60m",
"Lower_Oxy_T5_0.3_45m",
"Lower_Oxy_T3_0.3_25m",
"Chl_Max_T5_0.3_28m",
"Upper_Oxy_T5_0.3_35m",
"Upper_Oxy_T5_2.7_35m",
"Lower_Oxy_T5_2.7_45m",
"Chl_Max_T3_2.7_9m",
"Chl_Max_T3_0.3_9m",
"Upper_Oxy_T3_2.7_14m",
"Core_OMZ_T5_0.3_250m",
"Core_OMZ_T3_0.3_250m"
)
)


p <- ggplot(data=final_corrected1, aes(x=relab, y=id, fill=class))
f <- p + geom_bar(aes(y=id_new), stat="identity", position= "stack") + 
  #facet_wrap(~SampleType + SampleType2, scales = "free_y", nrow = 4, strip.position = "right") +
  #facet_grid(SampleType + SampleType2~. , scales = "free_y", space = "free_y") + 
  theme_bw() +
scale_fill_manual(values = colorRampPalette(brewer.pal(12, "Spectral"))(11)) +
  
  xlab("Relative abundance") + ylab(" ") +
  theme(legend.title = element_blank(), legend.position = "right") + 
   theme(legend.key.height = unit(0.5, "mm"))  +
   theme(legend.key.width  = unit(5, "mm"))  +
   theme(legend.key.size  = unit(0.3, "mm"))  +
   theme(legend.title = element_text(size = 9), 
               legend.text = element_text(size = 9)) +
    guides(fill=guide_legend(ncol = 1))  

f

```


# SOLO SEDIMENTS

```{r, message=FALSE}
final_corrected1 <- subset(final_corrected1,  ! paste(id_new,sep="_") %in% c("Upper_OMZ_T3_2.7_55m",
"Mesopelagic_T5_2.7_750m",
"Core_OMZ_T5_2.7_250m",
"Upper_OMZ_T5_2.7_60m",
"Lower_Oxy_T3_2.7_25m",
"Upper_OMZ_T3_0.3_55m",
"Mesopelagic_T3_2.7_750m",
"Mesopelagic_T5_0.3_750m",
"Mesopelagic_T3_0.3_750m",
"Upper_Oxy_T3_0.3_14m",
"Core_OMZ_T3_2.7_250m",
"Chl_Max_T5_2.7_28m",
"Upper_OMZ_T5_0.3_60m",
"Lower_Oxy_T5_0.3_45m",
"Lower_Oxy_T3_0.3_25m",
"Chl_Max_T5_0.3_28m",
"Upper_Oxy_T5_0.3_35m",
"Upper_Oxy_T5_2.7_35m",
"Lower_Oxy_T5_2.7_45m",
"Chl_Max_T3_2.7_9m",
"Chl_Max_T3_0.3_9m",
"Upper_Oxy_T3_2.7_14m",
"Core_OMZ_T5_0.3_250m",
"Core_OMZ_T3_0.3_250m"
) )
```


```{r cars}
# ORDEN DE ACUERDO A LA PROFUNDIDAD
final_corrected1$id_new <- factor(final_corrected1$id_new, levels = c(
"Hadal_Sed_H3_2_3cm_7890m",
"Bathyal_Sed_B04_1200m",
"Hadal_Sed_H4_1_2cm_8063m",
"Bathyal_Sed_B08_539m",
"Bathyal_Sed_B07_920m",
"Bathyal_Sed_B22_545m",
"Hadal_Sed_H3_0_1cm_7890m",
"Bathyal_Seds_B11_1113m",
"Bathyal_Sed_B05_957m",
"Bathyal_Sed_B12_529m",
"Hadal_Sed_H8_2_3cm_7734m",
"Hadal_Sed_H4_2_3cm_8063m",
"Hadal_Sed_H3_1_2cm_7890m",
"Hadal_Sed_H8_0_1cm_7734m",
"Hadal_Sed_H8_1_2cm_7734m",
"Hadal_Sed_H4_0_1cm_8063m"

)
)


p <- ggplot(data=final_corrected1, aes(x=relab, y=id, fill=class))
f <- p + geom_bar(aes(y=id_new), stat="identity", position= "stack") + 
  #facet_wrap(~SampleType + SampleType2, scales = "free_y", nrow = 4, strip.position = "right") +
  #facet_grid(SampleType + SampleType2~. , scales = "free_y", space = "free_y") + 
  theme_bw() +
scale_fill_manual(values = colorRampPalette(brewer.pal(12, "RdYlBu"))(11)) +
  
  
  xlab("Relative abundance") + ylab(" ") +
  theme(legend.title = element_blank(), legend.position = "right") + 
   theme(legend.key.height = unit(0.5, "mm"))  +
   theme(legend.key.width  = unit(5, "mm"))  +
   theme(legend.key.size  = unit(0.3, "mm"))  +
   theme(legend.title = element_text(size = 9), 
               legend.text = element_text(size = 9)) +
    guides(fill=guide_legend(ncol = 1))  

f
```


